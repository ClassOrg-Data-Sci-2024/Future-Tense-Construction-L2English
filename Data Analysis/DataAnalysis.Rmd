---
title: "FutureTenseConstructionL2English"
author: "Daniel Crawford"
date: "04/02/2024"
output: 
  github_document: 
    toc: TRUE
---


# Pull in final data


```{r}
#Import Packages
library(tidyverse)
```

```{r}


if (file.exists(paste0(dirname(getwd()),'/Data Files/FINAL_DATA_countruction_counts_and_student_info_with_scores.csv'))){
  print('Reading in File from directory')
  construction_counts = as_tibble(read.csv(paste0(dirname(getwd()),'/Data Files/FINAL_DATA_countruction_counts_and_student_info_with_scores.csv')))
}else{
 print('The final data dile you are looking for (FINAL_DATA_countruction_counts_and_student_info_with_scores.csv) does not appear to be in a directory.') 
}
  

```

```{r}
student_info = as_tibble(read.csv(url("https://github.com/ELI-Data-Mining-Group/PELIC-dataset/raw/master/corpus_files/student_information.csv")))
```

```{r}
if (file.exists(paste0(dirname(getwd()),'/large_data/pelic_compiled.csv'))){
  print('Reading in File from directory')
  PELIC_compiled = read.csv(paste0(dirname(getwd()),'/large_data/pelic_compiled.csv'))
}else{
  print('Reading in File from url')
  PELIC_compiled = as_tibble(read.csv(url("https://github.com/ELI-Data-Mining-Group/PELIC-dataset/raw/master/PELIC_compiled.csv"), fileEncoding = "ISO-8859-1"))
}

```


# Summary Statistics

```{r}
construction_counts %>% 
  select(count_will_construction, count_goingTo_construction) %>% 
  summarise_all(sum)
```



```{r}
#Get proportions
construction_props = construction_counts %>% 
  mutate(prop_goingTo_construction = count_goingTo_construction/(count_will_construction+count_goingTo_construction), .after = anon_id) %>% 
  mutate(prop_will_construction = count_will_construction/(count_will_construction+count_goingTo_construction), .after = anon_id)

construction_props

```


```{r}
#Raw Distributuion of Scores

construction_props %>% 
  select(LCT_Score, MTELP_I, MTELP_II, MTELP_III, MTELP_Conv_Score, Writing_Sample) %>% 
  pivot_longer(everything()) %>% 
  ggplot(aes(x = value)) +
  geom_histogram() +
  facet_wrap(~name)+
  labs(title = "Proficiency Score Distributions", x = "Value (Raw)", y = "Frequency") +
  theme_minimal()



construction_props %>% 
  select(Writing_Sample) %>% 
  pivot_longer(everything()) %>% 
  ggplot(aes(x = value)) +
  geom_histogram() +
  facet_wrap(~name)+
  labs(title = "Proficiency Score Distributions", x = "Value (Raw)", y = "Frequency") +
  theme_minimal()


```







```{r}
#Correlation of Proficiency Scores:

scaled_construction_props = construction_props %>% 
  select(anon_id, prop_will_construction, prop_goingTo_construction, LCT_Score, MTELP_I, MTELP_II, MTELP_III, MTELP_Conv_Score, Writing_Sample) %>% 
  mutate(across(-c(anon_id,prop_will_construction, prop_goingTo_construction), ~ scale(.x))) 
  
  
scaled_construction_props
```


```{r}

scaled_construction_props_30plus = construction_counts %>% 
  filter(count_will_construction+count_goingTo_construction >= 30) %>% 
  mutate(prop_goingTo_construction = count_goingTo_construction/(count_will_construction+count_goingTo_construction), .after = anon_id) %>% 
  mutate(prop_will_construction = count_will_construction/(count_will_construction+count_goingTo_construction), .after = anon_id) %>% 
  select(anon_id, prop_will_construction, prop_goingTo_construction, LCT_Score, MTELP_I, MTELP_II, MTELP_III, MTELP_Conv_Score, Writing_Sample) %>% 
  mutate(across(-c(anon_id,prop_will_construction, prop_goingTo_construction), ~ scale(.x)))
  

scaled_construction_props_30plus
```


```{r}
construction_props %>% 
  select(anon_id, prop_will_construction, prop_goingTo_construction, LCT_Score, MTELP_I, MTELP_II, MTELP_III, MTELP_Conv_Score, Writing_Sample)
```





# Correlation Analysis

```{r}
scaled_construction_props_30plus %>% 
  select(prop_will_construction, LCT_Score, MTELP_I, MTELP_II, MTELP_III, MTELP_Conv_Score, Writing_Sample) %>% 
  pivot_longer(-prop_will_construction) %>% 
  ggplot(aes(prop_will_construction, value))+
  geom_point()+
  facet_wrap(~name)+
  labs(title = "Proficiency Score Distributions (more than 30 uses of future tense)", x = "Proportion of 'will' construction", y = "Proficinecy Test Score")
```




```{r}
create_corr_diagram = function(scaled_construction_props_30plus, title_str){
  
  cm = as_tibble(cor(scaled_construction_props_30plus %>%  
           filter(!is.na(prop_will_construction)) %>%
           select(prop_will_construction, LCT_Score, MTELP_I, MTELP_II, MTELP_III, MTELP_Conv_Score, Writing_Sample)))
  
  

  cm %>% 
    mutate(score = colnames(cm)) %>%
    pivot_longer(!score) %>%
    mutate(value = round(value,2)) %>% 
    
    ggplot(aes(x = score, y = name, fill = value)) +
    
    geom_tile(color = "white") +
    scale_fill_gradient2(
      low = "blue",
      high = "red",
      mid = "white",
      midpoint = 0,
      limit = c(-1, 1),
      space = "Lab",
      name = "Pearson\nCorrelation"
    ) +
    theme_minimal() + # minimal theme
    theme(axis.text.x = element_text(
      angle = 45,
      vjust = 1,
      size = 12,
      hjust = 1
    )) +
    coord_fixed() +
    geom_text(aes(score, name, label = value),
              color = "black",
              size = 4) +
    theme(
      axis.title.x = element_blank(),
      axis.title.y = element_blank(),
      panel.grid.major = element_blank(),
      panel.border = element_blank(),
      panel.background = element_blank(),
      axis.ticks = element_blank(),
      legend.justification = c(1, 0),
      legend.direction = "horizontal"
    ) +
    guides(fill = guide_colorbar(
      barwidth = 7,
      barheight = 1,
      title.position = "top",
      title.hjust = 0.5
    ))+
    labs(title = paste0("Scaled Proficiency Scores Correlation (30 plus) - ",title_str))
    
}
```



```{r}
create_corr_diagram(scaled_construction_props_30plus, "All Langs")
```





```{r}
construction_props %>%
  #Get Only languages with at least 30 L1 speakers
  group_by(native_language) %>% 
  filter(n()>30) %>% 
  select(native_language, prop_will_construction, prop_goingTo_construction) %>% 
  
  summarise(across(everything(), .f = list(mean = mean), na.rm = TRUE)) %>% 
  pivot_longer(cols = starts_with('prop')) %>% 
  
  
  #Plotting
  mutate(name = str_split_i(name, "_",2)) %>% 
  arrange(desc(value)) %>% 
  mutate(Group = factor(native_language, levels = unique(native_language))) %>% 
  ggplot(aes(Group, value, fill = name))+
    geom_bar(stat = 'identity', position = 'dodge')+
    labs(title = "L1 In Future Tense Construction Proportion", x = "Native Language (L1)", y = "Proportion", fill = "Construction") +
    theme_minimal()
  
```


```{r}
scaled_construction_props_30plus_withL1 = scaled_construction_props_30plus %>% 
  left_join(construction_counts %>% select(anon_id, native_language), by = 'anon_id') %>% 
  group_by(native_language) %>% 
  filter(n()>10)

scaled_construction_props_30plus_withL1 %>% count(native_language)
```




```{r}
create_corr_diagram(
  scaled_construction_props_30plus_withL1 %>% filter(native_language == 'Arabic') %>% ungroup() %>%  select(-native_language,-anon_id), "Arabic")

create_corr_diagram(
  scaled_construction_props_30plus_withL1 %>% filter(native_language == 'Chinese') %>% ungroup() %>%  select(-native_language,-anon_id), "Chinese")

create_corr_diagram(
  scaled_construction_props_30plus_withL1 %>% filter(native_language == 'Japanese') %>% ungroup() %>%  select(-native_language,-anon_id), "Japanese")

create_corr_diagram(
  scaled_construction_props_30plus_withL1 %>% filter(native_language == 'Korean') %>% ungroup() %>%  select(-native_language,-anon_id), "Korean")

create_corr_diagram(
  scaled_construction_props_30plus_withL1 %>% filter(native_language == 'Thai') %>% ungroup() %>%  select(-native_language,-anon_id), "Thai")


```
# Random Intercepts Analysis

## Token Level Analysis

```{r}
if (file.exists(paste0(dirname(getwd()),'/large_data/tokenized_df_unnested.csv'))){
  print('Reading in File from directory')
  tokenized_df_unnested = read.csv(paste0(dirname(getwd()),'/large_data/tokenized_df_unnested.csv'))
}else{
  
  print('Creating tokenized_df_unnested - about 10 minute runtime.')
  # !!! WARNING - this will take about 10 - 15 !!!
  
  #Create tokenized_df, each row is a token
  tokenized_df_unnested = PELIC_compiled %>%
   #create tokenized df from the tok_lem_POS string
   mutate(tokenized_nested_df = map(tok_lem_POS, tlp_text_to_df)) %>%
   #keep the unique identifier of answer id
   select(answer_id, tokenized_nested_df) %>%
   #make the df longer and unndest
   unnest(tokenized_nested_df)

  # un-comment if you want to save
  #tokenized_df_unnested %>% write.csv('large_data/tokenized_df_unnested.csv')
}
```

```{r}
all_data = tokenized_df_unnested %>% 
  left_join(PELIC_compiled, by = 'answer_id') %>% 
  left_join(student_info, by = 'anon_id') %>% 
  left_join(scaled_construction_props, by = 'anon_id')
```


```{r}
future_tokens_data = all_data %>% 
  mutate(is_will_construction = if_else(trimws(lemma) == 'will' & trimws(POS) == 'MD', 1,0)) %>% 
  #if there is a 'going' token followed by 'to' then a verb within 2 words, put 1 in new column
  mutate(is_goingTo_construction = 
            if_else(
              token == "going" & lead(token) == "to" & (
                #lead allows to 'look ahead'
                startsWith(trimws(lead(POS, 2)), 'V') | 
                startsWith(trimws(lead(POS, 3)), 'V')
              ),1,0)) %>% 
  filter(is_goingTo_construction == 1 | is_will_construction == 1) %>% 
  mutate(mean_prof_score = rowMeans(select(.,LCT_Score, MTELP_Conv_Score, Writing_Sample), na.rm = T))

future_tokens_data
```

```{r}
intercepts_model <- lmer(is_will_construction ~ (1 | anon_id) + mean_prof_score, data = future_tokens_data)

model_coefs = coef(intercepts_model)$anon_id %>% 
  rename(Intercept = `(Intercept)`, Slope = mean_prof_score) %>% 
  rownames_to_column("anon_id")

model_coefs

```

```{r}
model_coefs %>% 
  left_join(student_info %>% select(anon_id, native_language), by = 'anon_id') %>% 
  group_by(native_language) %>% 
  filter(n()>30) %>% 
  left_join(future_tokens_data %>% select(anon_id, mean_prof_score), by = 'anon_id') %>% 
  ggplot()+
  geom_point(aes(x = mean_prof_score, y = Intercept)) +
  facet_wrap(~ native_language)
```

