---
title: "FutureTenseConstructionL2English"
author: "Daniel Crawford"
date: "04/02/2024"
output: 
  github_document: 
    toc: TRUE
---
EXISTING

# Correlation of Future Tense Construction Preference with Proficiency Scores for English L2 Learners

```{r}
#Import Packages
library(tidyverse)
```

### Load Data
Raw data can be found [here](https://github.com/ELI-Data-Mining-Group/PELIC-dataset/raw/master/PELIC_compiled.csv).

```{r}
#Read in Data from PELIC: 
PELIC_compiled = as_tibble(read.csv(url("https://github.com/ELI-Data-Mining-Group/PELIC-dataset/raw/master/PELIC_compiled.csv"), fileEncoding = "ISO-8859-1"))
nrow(PELIC_compiled)
ncol(PELIC_compiled)
head(PELIC_compiled)
```

The data contains about 46,000 entries, and a vast about of background data on the students. Of note will be L1, level, and profiency. 

```{r}
#Need to get demographic and proficiency scores for each student

student_info = as_tibble(read.csv(url("https://github.com/ELI-Data-Mining-Group/PELIC-dataset/raw/master/corpus_files/student_information.csv")))
nrow(student_info)
ncol(student_info)
head(student_info)
  
```

The student information for the 1,313 students expands on the demographics, and will be joined in later to the data. 

### Set the regex - these will likely change
```{r}

#RegEx for 'will' construction
RE_will = "will"

#RegEx for 'going to' construction
RE_goingto = "going to"

```


```{r}
will_lemmas = PELIC_compiled %>% 
  filter(str_detect(text, RE_will)) %>% 
  select(tok_lem_POS) %>% 
  mutate(code = str_extract_all(tok_lem_POS, "'will',[^\\)]*")) %>% 
  unnest(code) %>% 
  mutate(code = str_split_i(code, ",",-1)) %>% 
  select(code) %>% 
  count(code)

will_lemmas
  
```


```{r}

convert_to_list <- function(str) {
  return(gsub("[^[:alnum:]]","",unlist(strsplit(gsub("\\(|\\)", "", unlist(strsplit(gsub("^\\[|\\]$", "",str),","))), ",\\s*"))))
}


check_future <- function(vec){
  text = convert_to_list(vec)
  idx = match('going',text)
  
  
  if(!is.na(text[(idx+5)])){
    if(text[(idx+5)] == 'TO'){
      if(startsWith(text[(idx+8)],"V")){
        return('GoingToFuture')
      }else{
        return('GoingNoV')
      }
    }else{
      return('GoingNoTo')
    }
  }else{
   return('Error')
  }
    

}

```



```{r}
going_lemmas = PELIC_compiled %>% 
  slice(1:200) %>% 
  filter(str_detect(text, "going")) %>% 
  select(tok_lem_POS)

going_lemmas
```




```{r}
map(map(going_lemmas$tok_lem_POS,convert_to_list),check_future)
```



 


### Format the Data 
```{r}
PELIC_compiled %>% 
  #Optional Slicer - can have long run time if too many rows are used
  #slice(1:10) %>% 
  #Get just the id and the text - this is preferable and equivalent to having to concat all the text form a user
  select(anon_id,text) %>% 
  #Count number of occurrences of will construction
  mutate(will_ct = 
           map_int(text,
               ~ .x %>%
                  str_count(RE_will)
           )
  ) %>% 
  #Count number of occurrences going to constructions
  mutate(goingto_ct = 
           map_int(text,
               ~ .x %>%
                  str_count(RE_goingto)
           )
  ) %>% 
  #Group By individual
  group_by(anon_id) %>% 
  #sum the construction counts
  summarise_at(c("will_ct", "goingto_ct"),sum) %>% 
  left_join(
    (
      student_info %>% 
        select(anon_id,gender,gender,birth_year,native_language,yrs_in_english_environment,yrs_of_english_learning)
    ),
      by = 'anon_id'
    
  ) %>% 
  write.csv("working_data.csv")
        
```


My strategy for importing the data is to find construction in question in the text, and then to join in the student demographic information. The `working_data.csv` is the current end product of my data. 






# Session Info
```{r}
sessionInfo()
```

